# DeepSeek-R1 - DeepSeek 
DeepSeek-R1 is an advanced artificial intelligence model developed by the Chinese AI startup DeepSeek, focusing on reasoning capabilities. Here are its key features:
Open-Source and Licensing: DeepSeek-R1 is made available under an MIT license, which means it's fully open-source, allowing for free use, modification, and commercial application. 
  - Performance: This model has been engineered to perform comparably to OpenAI's o1 model in tasks involving math, code, and general reasoning. It's noted for achieving high accuracy rates in benchmarks like AIME, MATH-500, and SWE-bench Verified, showcasing its ability in complex problem-solving and logical reasoning.
  -Training Methodology: Unlike many models that rely heavily on supervised fine-tuning (SFT), DeepSeek-R1 leverages large-scale reinforcement learning (RL) in its post-training phase. This approach has allowed it to develop reasoning capabilities without large amounts of labeled data, leading to significant performance boosts.
  - Model Variants: DeepSeek-R1 comes in various sizes, including a base model (R1-Zero) and an enhanced version (R1), with smaller distilled models (ranging from 1.5B to 70B parameters) that cater to different computational resources. These distilled models maintain much of the reasoning power while being more efficient for local deployment.
  - Cost Efficiency: The model is cost-effective in terms of operation, with pricing significantly lower than that of its counterparts like OpenAI's o1, making AI reasoning more accessible.
  - Reasoning Transparency: One of the distinguishing features of DeepSeek-R1 is its ability to show its reasoning process, providing transparency in how it arrives at conclusions, which is beneficial for applications requiring explainability.
  - Global Implications: Its release has stirred discussions about AI development, particularly in the context of U.S.-China AI competition, highlighting how open-source models can challenge established market leaders.
  - DeepSeek R1 realease : https://api-docs.deepseek.com/news/news250120
  - DeepSeek n'échappe pas à la censure : https://www.francetvinfo.fr/internet/intelligence-artificielle/parlons-d-autre-chose-on-a-teste-l-ia-chinoise-deepseek-qui-n-echappe-pas-a-la-censure_7041479.html
  - 5 expériences DeepSeek-R1 : https://youtu.be/liESRDW7RrE?si=Kh4S2VOa_E_EAEus
  - Deepseek R1 vs Openai 01 : https://lightning.ai/akshay-ddods/studios/compare-deepseek-r1-and-openai-o1-using-rag?view=public&section=featured

# Qwen-2.5-VL - Alibaba Cloud 
Qwen-2.5-VL is a series of vision-language models (VLMs) developed by the Qwen team at Alibaba Cloud, representing an advancement over its predecessors in terms of visual understanding and interaction capabilities. 
  - Multimodal Abilities: Qwen-2.5-VL integrates both visual and language processing, enabling the model to understand and interact with both text and visual data effectively. It can analyze charts, recognize objects in various contexts, and interpret complex visual information like documents, invoices, and forms.
  - Model Sizes: The series includes models with three parameter sizes: 3 billion (3B), 7 billion (7B), and 72 billion (72B). This range allows for different use cases from edge devices to high-performance computing environments.
  - Performance: According to benchmarks, Qwen-2.5-VL outperforms several notable models like OpenAI's GPT-4o, Anthropic's Claude 3.5 Sonnet, and Google's Gemini 2.0 Flash in areas like video understanding, document analysis, and math problem-solving. It's particularly noted for its document parsing capabilities, being able to handle multi-scene, multilingual texts, and various document types including handwritten notes, tables, charts, chemical formulas, and music sheets.
  - Interactive Capabilities: One of the standout features is its ability to interact with software on both PCs and mobile devices. It can perform tasks like booking flights through apps or switching between applications on Linux desktops, showcasing its potential in automated operations based on visual inputs and text instructions.
  - Licensing and Availability: The smaller models (3B and 7B) are available under a permissive license, while the 72B model is under a custom Alibaba license which requires companies with over 100 million monthly active users to seek permission for commercial deployment.
  - Restrictions: Being developed by a Chinese company, Qwen-2.5-VL has restrictions on discussing certain topics, particularly sensitive political subjects, as seen in its refusal to discuss "Xi Jinping's mistakes" in the Qwen Chat app.
  - Dynamic Resolution: The model supports Naive Dynamic Resolution, which means it can process images of different resolutions by dynamically adjusting the number of visual tokens, closely mimicking human visual processing.
  -Video Understanding: It can handle and comprehend videos over an hour long, with capabilities to pinpoint specific moments or events within videos, enhancing its utility in video-based tasks like question answering or content creation.
  - Applications:
Automation: Useful in scenarios where visual and text data need to be processed for automated actions, like in customer service for handling invoices or in educational software for interactive learning.
Content Analysis: Its ability to interpret visual content makes it suitable for applications in media, entertainment, or any sector requiring detailed content analysis from images or videos.
Software Interaction: The model's capability to control software applications can be leveraged in IoT, smart home systems, or any environment where AI interaction with digital interfaces is beneficial.
  - Qwen 2.5 VL release : https://qwenlm.github.io/blog/qwen2.5-vl/
  - Github : https://github.com/QwenLM/Qwen2.5?tab=readme-ov-file


